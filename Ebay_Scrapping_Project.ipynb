{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9873202-1f81-4108-8c1d-f77aee68faa9",
   "metadata": {},
   "source": [
    "# eBay Product Scraper with Automated Email Notifications\n",
    "\n",
    "This script scrapes product information from a ebay and sends email notifications when the price falls below a certain threshold. It uses OAuth 2.0 for secure email sending via Gmail.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "*   Web scraping using BeautifulSoup and requests.\n",
    "*   Price cleaning using regular expressions.\n",
    "*   Email notifications using Gmail API and OAuth 2.0.\n",
    "*   Data storage in CSV format (implementation not shown in this snippet but can be easily added).\n",
    "*   Robust error handling and logging.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "*   `beautifulsoup4`\n",
    "*   `requests`\n",
    "*   `google-api-python-client`\n",
    "*   `google-auth-httplib2`\n",
    "*   `google-auth-oauthlib`\n",
    "*   `flask` (if using the web interface)\n",
    "\n",
    "## Configuration\n",
    "\n",
    "The following configurations should ideally be stored in a separate configuration file or environment variables for security and maintainability:\n",
    "\n",
    "*   `client_secret.json`: OAuth 2.0 client secrets file (downloaded from Google Cloud Console).\n",
    "*   `token.pickle`: Stores OAuth 2.0 tokens (generated during authorization).\n",
    "*   `TARGET_URL`: URL of the product to scrape.\n",
    "*   `PRICE_THRESHOLD`: The price below which an email notification is sent.\n",
    "*   `SENDER_EMAIL`: Your Gmail address.\n",
    "*   `RECIPIENT_EMAIL`: Recipient's email address.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84efb821-a505-4e24-a655-9c8e8825453f",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "This project utilizes a variety of Python libraries to achieve its functionality. Below is an explanation of the imported libraries:\n",
    "\n",
    "- **`bs4` (BeautifulSoup)**: For parsing and extracting data from HTML and XML documents.\n",
    "- **`requests`**: To make HTTP requests for web scraping and API calls.\n",
    "- **`time`**: For handling delays and measuring time intervals.\n",
    "- **`datetime`**: To work with date and time objects.\n",
    "- **`csv`**: For reading from and writing to CSV files.\n",
    "- **`re`**: Regular expressions for pattern matching and text processing.\n",
    "- **`smtplib`**: For sending emails using the Simple Mail Transfer Protocol (SMTP).\n",
    "- **`googleapiclient.discovery`**: To access Google APIs such as Gmail.\n",
    "- **`google_auth_oauthlib.flow`**: For managing the OAuth 2.0 authentication flow.\n",
    "- **`google.auth.transport.requests`**: For making authenticated HTTP requests.\n",
    "- **`email.mime.text`**: To create email messages in MIME format.\n",
    "- **`base64`**: To encode and decode data in Base64 format.\n",
    "- **`pickle`**: For serializing and deserializing Python objects.\n",
    "- **`os`**: To interact with the operating system (e.g., file paths).\n",
    "\n",
    "These libraries collectively enable the project to perform tasks such as:\n",
    "- Web scraping,\n",
    "- Data manipulation,\n",
    "- Email automation, and\n",
    "- API integration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93d9e617-5dc4-46d4-ba9c-ab8d49af1cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import datetime\n",
    "import csv\n",
    "import re\n",
    "import smtplib\n",
    "from datetime import date\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from email.mime.text import MIMEText\n",
    "import base64\n",
    "import pickle\n",
    "import os\n",
    "import schedule\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa84d0b-f9c6-4bca-a7e2-289c6ce96e9f",
   "metadata": {},
   "source": [
    "# Gmail API Integration for Notifications\n",
    "\n",
    "This block integrates the Gmail API to send email notifications. Key highlights:\n",
    "\n",
    "- **OAuth 2.0 Authentication**: Ensures secure access to Gmail using credentials (`client_secret.json`).\n",
    "- **Key Functions**:\n",
    "  - `create_message(sender, to, subject, message_text)`: Creates an email message.\n",
    "  - `send_message(service, user_id, message)`: Sends the email message using Gmail API.\n",
    "  - `send_mail(product_name, price, product_link)`: Automates email notifications when a product matches the desired price.\n",
    "\n",
    "### Required Steps:\n",
    "1. Download and set up the `client_secret.json` file from Google Cloud Console.\n",
    "2. Authenticate with Google API to generate a token.\n",
    "3. Specify the sender and receiver email addresses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58a531ff-f8eb-4c58-8340-3e5cac5f5c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with the path to your downloaded credentials.json file\n",
    "CREDENTIALS_FILE = r'client_secret.json'\n",
    "\n",
    "# If modifying these scopes, delete the token.pickle file.\n",
    "SCOPES = ['https://www.googleapis.com/auth/gmail.send']\n",
    "\n",
    "\n",
    "\n",
    "def create_message(sender, to, subject, message_text):\n",
    "    \"\"\"Creates a MIMEText email message.\"\"\"\n",
    "    message = MIMEText(message_text)\n",
    "    message['to'] = to\n",
    "    message['from'] = sender\n",
    "    message['subject'] = subject\n",
    "    raw_message = {'raw': base64.urlsafe_b64encode(message.as_bytes()).decode()}\n",
    "    return raw_message\n",
    "\n",
    "\n",
    "def send_message(service, user_id, message):\n",
    "    \"\"\"Sends an email message.\n",
    "\n",
    "    Args:\n",
    "      service: The authorized Gmail API service instance.\n",
    "      user_id: The user's email address.\n",
    "      message: The email message to be sent.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        message = (service.users().messages().send(userId=user_id, body=message)\n",
    "                   .execute())\n",
    "        print(f'Message Id: {message[\"id\"]}')\n",
    "        return message\n",
    "    except Exception as error:\n",
    "        print(f'An error occurred: {error}')\n",
    "        return None\n",
    "\n",
    "\n",
    "def send_mail(product_name,price,product_link):\n",
    "    \"\"\"Sends an email using OAuth 2.0 authentication.\"\"\"\n",
    "\n",
    "    # Get credentials from token or authorization flow\n",
    "    creds = None\n",
    "    if os.path.exists('token.pickle'):\n",
    "        with open('token.pickle', 'rb') as token:\n",
    "            creds = pickle.load(token)\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                CREDENTIALS_FILE, SCOPES)\n",
    "            creds = flow.run_local_server(port=0) # specify port if using localhost\n",
    "        with open('token.pickle', 'wb') as token:\n",
    "            pickle.dump(creds, token)\n",
    "    # Build the Gmail API service object\n",
    "    service = build('gmail', 'v1', credentials=creds)\n",
    "\n",
    "    # Define email content\n",
    "    sender = \"mubashirahmed421@gmail.com\"  # Replace with your Gmail address\n",
    "    receiver = \"mubashirshakeel312@gmail.com\" # Replace with the receiver email\n",
    "    subject = f\"The {product_name} you want is below {price}! Now is your chance to buy!\"\n",
    "    body = f\" This is the moment we have been waiting for. Now is your chance to pick up the {product_name} of your dreams. Don't mess it up! Link here: {product_link}\"\n",
    "\n",
    "    # Create message object\n",
    "    message = create_message(sender, receiver, subject, body)\n",
    "\n",
    "    # Send the email\n",
    "    send_message(service, \"me\", message)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2034ad0f-fa76-4fbc-8ee8-7fad6fc47027",
   "metadata": {},
   "source": [
    "# Cleaning and Processing Price Data\n",
    "\n",
    "Web-scraped prices often contain currency symbols, commas, or other non-numeric characters. \n",
    "This block provides a function to clean such data and extract valid price information.\n",
    "\n",
    "### Function Details:\n",
    "- **`clean_price(price_str)`**:\n",
    "  - Strips out unnecessary characters.\n",
    "  - Extracts valid numeric characters and decimal points.\n",
    "  - Returns the price as a floating-point number.\n",
    "  - Handles `None` or invalid inputs gracefully by returning `0`.\n",
    "\n",
    "### Examples:\n",
    "- **Input**: `$12.99` → **Output**: `12.99`\n",
    "- **Input**: `1,234.56` → **Output**: `1234.56`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "583d2263-9d93-44f4-a003-f9bd73da8b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1299, 1000, 2550, 0, 123456, 12300, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Function to clean price\n",
    "def clean_price(price_str):\n",
    "    if price_str is None:\n",
    "        return 0\n",
    "    cleaned_price = re.sub(r'[^\\d.]', '', price_str)\n",
    "    try:\n",
    "        return int(float(cleaned_price) * 100)  # Convert to integer cents\n",
    "    except ValueError:\n",
    "        return 0\n",
    "\n",
    "# Example usage:\n",
    "prices = [\"$12.99\", \"£10\", \"€25.50\", \"Free\", \"1,234.56\", \"123 abc\", None, \"\"]\n",
    "cleaned_prices = [clean_price(price) for price in prices]\n",
    "print(cleaned_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fb9e89-2a7c-40fa-92b5-ac05022774bf",
   "metadata": {},
   "source": [
    "## Function: `scrap_product_list`\n",
    "\n",
    "### Purpose:\n",
    "Scrapes product data from eBay based on the provided product name, shoe size, and desired price. Saves the data to a CSV file and sends an email if the total price meets the desired criteria.\n",
    "\n",
    "### Parameters:\n",
    "- **`product_name`**: The name of the product to search for.\n",
    "- **`shoe_size`**: The desired shoe size for filtering the results.\n",
    "- **`desired_price`**: The maximum acceptable price (including delivery charges).\n",
    "- **`relevency_filter`**: *(Optional)* A filter for sorting results by relevance. Default is `15`.\n",
    "\n",
    "### Key Steps:\n",
    "1. Formats the product name to create a valid search query.\n",
    "2. Creates a CSV file (`product.csv`) if it doesn’t already exist, with the following columns:\n",
    "   - Product Name\n",
    "   - Price\n",
    "   - Delivery Charges\n",
    "   - Product Link\n",
    "   - Image\n",
    "   - Date\n",
    "3. Sends an HTTP request to eBay and parses the search results using BeautifulSoup.\n",
    "4. Extracts details for each product, such as:\n",
    "   - Name\n",
    "   - Price\n",
    "   - Delivery cost\n",
    "   - Product link\n",
    "   - Image URL\n",
    "5. Cleans the price and delivery charges.\n",
    "6. Sends an email notification if the total price (price + delivery) is within the desired price range.\n",
    "7. Appends the data to the `product.csv` file.\n",
    "\n",
    "### Output:\n",
    "- Scraped product details saved to `product.csv`.\n",
    "- Email notifications sent when conditions are met.\n",
    "\n",
    "### Example:\n",
    "```python\n",
    "scrap_product_list(\"Nike Shoes\", \"10\", 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1eb40bab-3b50-4357-9b51-bb1738b5e4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrap data\n",
    "def scrap_product_list(product_name, shoe_size, desired_price, relevency_filter=15):\n",
    "    product = re.sub(r\"\\s+\", \"+\", product_name)\n",
    "    csv_file = 'product.csv'\n",
    "    \n",
    "    # Ensure CSV has header row\n",
    "    if not os.path.exists(csv_file):\n",
    "        with open(csv_file, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"Product Name\", \"Price\", \"Delivery Charges\", \"Product Link\", \"Image\", \"Date\"])\n",
    "    \n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "    main_url = f'https://www.ebay.com/sch/i.html?_from=R50&_nkw={product}&_sacat=0&_dcat=15709&_sop={relevency_filter}&_ipg=120&US%2520Shoe%2520Size={shoe_size}&_pgn=1'\n",
    "    print(f\"Scraping URL: {main_url}\")\n",
    "    page = requests.get(main_url, headers=headers)\n",
    "    soup1 = BeautifulSoup(page.content, 'html.parser')\n",
    "    soup2 = BeautifulSoup(soup1.prettify(), 'html.parser')\n",
    "    container = soup2.find('ul', class_='srp-results')\n",
    "    if not container:\n",
    "        print(\"No results found.\")\n",
    "        return\n",
    "\n",
    "    cards = container.find_all('li', class_='s-item__pl-on-bottom')\n",
    "\n",
    "    for card in cards:\n",
    "        product_link = card.find('a').get('href')\n",
    "        image = card.find('img').get('src')\n",
    "        name = card.find('div', class_='s-item__title').text.strip()\n",
    "        price = card.find('span', class_='s-item__price').text.strip()\n",
    "        delivery = card.find('span', class_='s-item__logisticsCost').text.strip() if card.find('span', class_='s-item__logisticsCost') else \"0\"\n",
    "        today = date.today()\n",
    "\n",
    "        cleaned_price = clean_price(price)\n",
    "        cleaned_delivery = clean_price(delivery)\n",
    "        total_price = cleaned_delivery + cleaned_price\n",
    "\n",
    "        # Send email if total price is within desired range\n",
    "        if total_price <= int(desired_price) * 100 and product_name.lower() in name.lower():  # Convert desired_price to cents for comparison\n",
    "            send_mail(name, f\"${cleaned_price / 100:.2f}\", product_link)\n",
    "\n",
    "        # Write data to CSV\n",
    "        with open(csv_file, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow([name, f\"${cleaned_price / 100:.2f}\", f\"${cleaned_delivery / 100:.2f}\", product_link, image, today])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c78d509-0a45-46b7-b484-1bf688639f7f",
   "metadata": {},
   "source": [
    "## Function: `daily_scraping_job`\n",
    "\n",
    "### Purpose:\n",
    "\n",
    "Runs the `scrap_product_list` function daily to scrape product data and save it.\n",
    "\n",
    "### Parameters:\n",
    "\n",
    "*   `product_name` (string): The name of the product to scrape daily.\n",
    "*   `shoe_size` (string): The desired shoe size for filtering the results.\n",
    "*   `desired_price` (number): The maximum acceptable price (including delivery charges).\n",
    "\n",
    "### Usage:\n",
    "\n",
    "This function is used in combination with the `schedule_scraping` function to run the scraping process at a scheduled time.\n",
    "\n",
    "### Example:\n",
    "\n",
    "```python\n",
    "daily_scraping_job(\"Nike Shoes\", \"10\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e06da2e2-141f-4e30-bc35-57fd5ce8c1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run daily\n",
    "def daily_scraping_job(product_name, shoe_size, desired_price):\n",
    "    scrap_product_list(product_name, shoe_size, desired_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e030d6d1-d0ce-49d4-ab31-2da165d8827d",
   "metadata": {},
   "source": [
    "## Function: `schedule_scraping`\n",
    "\n",
    "### Purpose:\n",
    "\n",
    "Schedules the `daily_scraping_job` function to run at a specified time every day.\n",
    "\n",
    "### Parameters:\n",
    "\n",
    "*   `product_name` (string): The name of the product to scrape.\n",
    "*   `shoe_size` (string): The desired shoe size for filtering the results.\n",
    "*   `desired_price` (number): The maximum acceptable price (including delivery charges).\n",
    "*   `time_of_day` (string): The time of day when the scraping job should run (in `HH:MM` format, 24-hour clock).\n",
    "\n",
    "### How It Works:\n",
    "\n",
    "*   Uses the `schedule` library to set up a recurring daily task.\n",
    "*   Automatically executes the `daily_scraping_job` function at the specified time.\n",
    "\n",
    "### Example:\n",
    "\n",
    "```python\n",
    "schedule_scraping(\"Nike Shoes\", \"10\", 100, \"08:00\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dccaeeaf-ff15-4e1f-9e16-f03c80433fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schedule the job dynamically\n",
    "def schedule_scraping(product_name, shoe_size, desired_price, time_of_day):\n",
    "    schedule.every().day.at(time_of_day).do(daily_scraping_job, product_name, shoe_size, desired_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce71e973-a788-43eb-bcfd-0469898232c8",
   "metadata": {},
   "source": [
    "## Main Execution Block\n",
    "\n",
    "### Purpose:\n",
    "This is the entry point of the program, where user inputs are taken, and the scraping job is scheduled to run daily at a specified time.\n",
    "\n",
    "### Key Steps:\n",
    "1. **User Inputs**:\n",
    "   - Prompts the user for:\n",
    "     - **Product Name**: The item to search for.\n",
    "     - **Shoe Size**: Desired shoe size for filtering results.\n",
    "     - **Desired Price**: The maximum price the user is willing to pay (in USD).\n",
    "     - **Time of Day**: The daily schedule time in `HH:MM` format (24-hour clock).\n",
    "\n",
    "2. **Job Scheduling**:\n",
    "   - Calls the `schedule_scraping` function to schedule the daily scraping task with the user's inputs.\n",
    "\n",
    "3. **Scheduler Execution**:\n",
    "   - Keeps the scheduler running continuously to ensure the scraping task is executed at the specified time.\n",
    "\n",
    "4. **Notifications**:\n",
    "   - Displays messages to confirm successful scheduling and informs the user that the scheduler is running.\n",
    "\n",
    "### Example Workflow:\n",
    "1. The user enters:\n",
    "   - Product Name: `Nike Shoes`\n",
    "   - Shoe Size: `10`\n",
    "   - Desired Price: `100`\n",
    "   - Time of Day: `08:00`\n",
    "2. The program schedules the job and prints:\n",
    "\n",
    "### Notes:\n",
    "- To stop the scheduler, press **Ctrl+C**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdc4900-d59a-49ba-8259-bac80b5df2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the product name:  Air Jordan XX3\n",
      "Enter the shoe size:  9\n",
      "Enter your desired price (USD):  150\n",
      "Enter the time to run the job daily (HH:MM, 24-hour format):  05:59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduled scraping for 'Air Jordan XX3' at 05:59 daily.\n",
      "Scheduler is running. Press Ctrl+C to stop.\n",
      "Scraping URL: https://www.ebay.com/sch/i.html?_from=R50&_nkw=Air+Jordan+XX3&_sacat=0&_dcat=15709&_sop=15&_ipg=120&US%2520Shoe%2520Size=9&_pgn=1\n",
      "Message Id: 1941a395d7524a75\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example variables (replace with user inputs during presentation)\n",
    "    product_name = input(\"Enter the product name: \")\n",
    "    shoe_size = input(\"Enter the shoe size: \")\n",
    "    desired_price = input(\"Enter your desired price (USD): \")\n",
    "    time_of_day = input(\"Enter the time to run the job daily (HH:MM, 24-hour format): \")\n",
    "\n",
    "    # Schedule the scraping job\n",
    "    schedule_scraping(product_name, shoe_size, desired_price, time_of_day)\n",
    "    print(f\"Scheduled scraping for '{product_name}' at {time_of_day} daily.\")\n",
    "\n",
    "    # Keep the scheduler running\n",
    "    print(\"Scheduler is running. Press Ctrl+C to stop.\")\n",
    "    while True:\n",
    "        schedule.run_pending()\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dd1d59-53fd-4afe-a2ca-26fec750fee3",
   "metadata": {},
   "source": [
    "### Script Output\n",
    "\n",
    "The script generates two main outputs:\n",
    "\n",
    "1. **CSV File**:  \n",
    "   The scraped data is saved in a CSV file (`product.csv`). The CSV file contains the following columns:  \n",
    "   - **Product Name**  \n",
    "   - **Price**  \n",
    "   - **Delivery Charges**  \n",
    "   - **Product Link**  \n",
    "   - **Image**  \n",
    "   - **Date**  \n",
    "\n",
    "   Below is a screenshot of the generated CSV file:\n",
    "\n",
    "   ![CSV Output](csv_output.jpg)\n",
    "\n",
    "---\n",
    "\n",
    "2. **Email Notification**:  \n",
    "   When a product's total price (price + delivery charges) is within the desired range, the script sends an email notification. The email contains:  \n",
    "   - **Product Name**  \n",
    "   - **Price**  \n",
    "   - **Product Link**  \n",
    "\n",
    "   Below is a screenshot of an email sent by the script:\n",
    "\n",
    "   ![Email Output](email_output.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba004a31-ab2d-4ec8-8131-1069a8d0fe4d",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "The script is designed for demonstration purposes and may require adjustments for production use. Ensure compliance with eBay’s and Gmail’s terms of service when using this script.\n",
    "\n",
    "## Future Enhancements\n",
    "\n",
    "*   Support for multiple product searches in a single run.\n",
    "*   Integration with other email services (e.g., Outlook, Yahoo).\n",
    "*   Improved error handling and logging mechanisms.\n",
    "*   Better Structured email.\n",
    "*   Support for scraping multiple e-commerce websites.\n",
    "\n",
    "## Acknowledgments\n",
    "\n",
    "This project utilizes open-source libraries and the Gmail API to demonstrate web scraping and automated notifications. Special thanks to the Python and developer community for their resources and support."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
